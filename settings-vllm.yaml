#server:
#  env_name: ${APP_ENV:vllm}

llm:
  mode: openailike

#embedding:
#  mode: huggingface
#  ingest_mode: simple

embedding:
  mode: local
  ingest_mode: simple

local:
  embedding_hf_model_name: BAAI/bge-small-en-v1.5

openai:
  api_base: http://localhost:1234/v1 # LM Studio base URL
  api_key: EMPTY
  model: mixtral  # this can be whatever you want